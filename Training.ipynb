{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOxpxIeJZWB5C48CFlfGudA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"67T9D33nzYL4","executionInfo":{"status":"ok","timestamp":1754205685741,"user_tz":-330,"elapsed":19924,"user":{"displayName":"Project","userId":"07677140663822526186"}},"outputId":"c12ace84-debb-4ea0-d168-300bcc3f5ab3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-74f8b3ea-2b46-4868-ac87-99ef30ca5387\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-74f8b3ea-2b46-4868-ac87-99ef30ca5387\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle.json to kaggle.json\n"]},{"output_type":"execute_result","data":{"text/plain":["{'kaggle.json': b'{\"username\":\"jiyaparmar04\",\"key\":\"f0c150fcf6b3e85cc011ec252d6a2cf6\"}'}"]},"metadata":{},"execution_count":1}],"source":["from google.colab import files\n","\n","files.upload()"]},{"cell_type":"code","source":["# Install the Kaggle library\n","!pip install -q kaggle\n","\n","# Set up the Kaggle directory\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","\n","# Download the dataset\n","!kaggle datasets download -d paramaggarwal/fashion-product-images-small\n","\n","# Unzip the dataset\n","!unzip -q fashion-product-images-small.zip -d fashion-dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2feRFmiIzd7K","executionInfo":{"status":"ok","timestamp":1754205757976,"user_tz":-330,"elapsed":49254,"user":{"displayName":"Project","userId":"07677140663822526186"}},"outputId":"8a2fe8fe-9fca-4024-e40a-84af0be825f1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset URL: https://www.kaggle.com/datasets/paramaggarwal/fashion-product-images-small\n","License(s): MIT\n","Downloading fashion-product-images-small.zip to /content\n"," 96% 544M/565M [00:01<00:00, 320MB/s]\n","100% 565M/565M [00:01<00:00, 328MB/s]\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import models, transforms\n","from PIL import Image\n","import pandas as pd\n","import os\n","import time\n","\n","#Custom Dataset for the Kaggle Dataset\n","class KaggleFashionDataset(Dataset):\n","    def __init__(self, root_dir, annotations_file, transform=None):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","\n","        # Load annotations and drop rows with missing images\n","        self.annotations = pd.read_csv(annotations_file, on_bad_lines='skip')\n","        self.annotations['image_path'] = self.annotations.apply(lambda row: os.path.join(self.root_dir, 'images', str(row['id']) + '.jpg'), axis=1)\n","        self.annotations = self.annotations[self.annotations['image_path'].apply(os.path.exists)]\n","\n","        # Create a mapping from category name to a unique index\n","        self.classes = self.annotations['subCategory'].unique().tolist()\n","        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n","\n","    def __len__(self):\n","        return len(self.annotations)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.annotations.iloc[idx]['image_path']\n","        image = Image.open(img_path).convert('RGB')\n","\n","        label_name = self.annotations.iloc[idx]['subCategory']\n","        label = self.class_to_idx[label_name]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label\n","\n","# 2. Setup\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","data_transforms = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","# 3. Data Loading\n","data_dir = 'fashion-dataset'\n","annotations_file = os.path.join(data_dir, 'styles.csv')\n","dataset = KaggleFashionDataset(root_dir=data_dir, annotations_file=annotations_file, transform=data_transforms)\n","\n","dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=2)\n","class_names = dataset.classes\n","print(f\"Training on {len(dataset)} images.\")\n","print(f\"Total classes: {len(class_names)}\")\n","\n","#  4. Model Fine-Tuning\n","model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n","num_ftrs = model.fc.in_features\n","model.fc = nn.Linear(num_ftrs, len(class_names))\n","model = model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","#  5. Training Loop\n","def train_model(model, criterion, optimizer, num_epochs=5):\n","    since = time.time()\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch+1}/{num_epochs}')\n","        print('-' * 10)\n","        model.train()\n","        running_loss = 0.0\n","        running_corrects = 0\n","        for inputs, labels in dataloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            with torch.set_grad_enabled(True):\n","                outputs = model(inputs)\n","                _, preds = torch.max(outputs, 1)\n","                loss = criterion(outputs, labels)\n","                loss.backward()\n","                optimizer.step()\n","            running_loss += loss.item() * inputs.size(0)\n","            running_corrects += torch.sum(preds == labels.data)\n","        epoch_loss = running_loss / len(dataloader.dataset)\n","        epoch_acc = running_corrects.double() / len(dataloader.dataset)\n","        print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","    time_elapsed = time.time() - since\n","    print(f'\\nTraining complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n","    torch.save(model.state_dict(), 'kaggle_fashion_model.pth')\n","    print(\"Model saved to kaggle_fashion_model.pth\")\n","\n","if __name__ == '__main__':\n","    train_model(model, criterion, optimizer, num_epochs=5)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RYfLZ93Mztm5","executionInfo":{"status":"ok","timestamp":1754206520248,"user_tz":-330,"elapsed":758730,"user":{"displayName":"Project","userId":"07677140663822526186"}},"outputId":"ab3e497c-d74a-43f9-c21f-901ec4537037"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda:0\n","Training on 44419 images.\n","Total classes: 45\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 62.7MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","----------\n","Train Loss: 0.5512 Acc: 0.8710\n","Epoch 2/5\n","----------\n","Train Loss: 0.2186 Acc: 0.9451\n","Epoch 3/5\n","----------\n","Train Loss: 0.1655 Acc: 0.9579\n","Epoch 4/5\n","----------\n","Train Loss: 0.1314 Acc: 0.9659\n","Epoch 5/5\n","----------\n","Train Loss: 0.1127 Acc: 0.9703\n","\n","Training complete in 12m 22s\n","Model saved to kaggle_fashion_model.pth\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7OyHBO00z6pG","executionInfo":{"status":"ok","timestamp":1754206857289,"user_tz":-330,"elapsed":4636,"user":{"displayName":"Project","userId":"07677140663822526186"}},"outputId":"db66d2e6-6b0f-402f-9425-51eab5464e41"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!cp kaggle_fashion_model.pth \"/content/drive/MyDrive/\"\n"],"metadata":{"id":"Fh3FzKcT27g8","executionInfo":{"status":"ok","timestamp":1754206680171,"user_tz":-330,"elapsed":1253,"user":{"displayName":"Project","userId":"07677140663822526186"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torchvision import models, transforms\n","from PIL import Image\n","import pandas as pd\n","import os\n","\n","# 1. Setup\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","#  2. Get Class Names from the Dataset\n","if not os.path.exists('fashion-dataset'):\n","    print(\"Dataset not found. Unzipping from Google Drive...\")\n","    pass\n","\n","try:\n","    annotations_file = 'fashion-dataset/styles.csv'\n","    df = pd.read_csv(annotations_file, on_bad_lines='skip')\n","    class_names = df['subCategory'].unique().tolist()\n","    print(f\"Found {len(class_names)} classes.\")\n","except FileNotFoundError:\n","    print(\"Error: 'fashion-dataset/styles.csv' not found. Please re-run the Kaggle download steps.\")\n","    class_names = []\n","\n","#  3. Define Model Architecture\n","# This must be the same architecture as the one used for training.\n","model = models.resnet18(weights=None)\n","num_ftrs = model.fc.in_features\n","if class_names:\n","    model.fc = nn.Linear(num_ftrs, len(class_names))\n","model = model.to(device)\n","\n","#  4. Load the Trained Weights\n","# Load the state_dict from your Google Drive\n","model_path = '/content/drive/MyDrive/kaggle_fashion_model.pth'\n","try:\n","    model.load_state_dict(torch.load(model_path, map_location=device))\n","    model.eval()\n","    print(\"Model weights loaded successfully.\")\n","except FileNotFoundError:\n","    print(f\"Error: Model file not found at {model_path}. Make sure it was saved correctly.\")\n","\n","#  5. Define Prediction Transforms\n","# These must be the same as the training transforms.\n","prediction_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","#  6. Prediction Function\n","def predict_image(image_path, model, transform, class_list):\n","    if not class_list or model.fc is None:\n","        return \"Model or class list not loaded correctly.\"\n","\n","    image = Image.open(image_path).convert('RGB')\n","    image_tensor = transform(image).unsqueeze(0).to(device)\n","\n","    with torch.no_grad():\n","        outputs = model(image_tensor)\n","        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n","        _, predicted_idx = torch.max(outputs, 1)\n","\n","    predicted_class = class_list[predicted_idx.item()]\n","    confidence = probabilities[0][predicted_idx.item()].item()\n","\n","    return predicted_class, confidence\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zMXeCEht3aqm","executionInfo":{"status":"ok","timestamp":1754206700542,"user_tz":-330,"elapsed":1543,"user":{"displayName":"Project","userId":"07677140663822526186"}},"outputId":"1d7465de-47b6-4e6e-d6c1-6d572541b7fa"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda:0\n","Found 45 classes.\n","Model weights loaded successfully.\n"]}]},{"cell_type":"code","source":["\n","from google.colab import files\n","\n","# Upload your image\n","uploaded = files.upload()\n","\n","# Get the filename of the uploaded image\n","if uploaded:\n","    image_filename = next(iter(uploaded))\n","    print(f\"\\nUploaded '{image_filename}'\")\n","\n","    # Make a prediction\n","    predicted_category, confidence = predict_image(image_filename, model, prediction_transform, class_names)\n","\n","    print(f\"\\nPredicted Category: {predicted_category}\")\n","    print(f\"Confidence: {confidence*100:.2f}%\")\n","else:\n","    print(\"No file uploaded.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":160},"id":"XOyPUzbz3ffk","executionInfo":{"status":"ok","timestamp":1754206780430,"user_tz":-330,"elapsed":28579,"user":{"displayName":"Project","userId":"07677140663822526186"}},"outputId":"059c9750-6ea8-42aa-c2dd-ec429e197dcf"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-b90b2d94-ea81-4324-93c3-35ebfc916e6f\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-b90b2d94-ea81-4324-93c3-35ebfc916e6f\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving Image_9.jpg to Image_9.jpg\n","\n","Uploaded 'Image_9.jpg'\n","\n","Predicted Category: Shoes\n","Confidence: 99.63%\n"]}]},{"cell_type":"code","source":["# Stage your files\n","!git add .\n","\n","# Commit your work\n","!git commit -m \"Your commit message\"\n","\n","# Push to GitHub\n","!git push origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xdgFRRGu6Lnp","executionInfo":{"status":"ok","timestamp":1754207441061,"user_tz":-330,"elapsed":1670,"user":{"displayName":"Project","userId":"07677140663822526186"}},"outputId":"59c04227-3edd-4236-fa95-babf0f41ae74"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","nothing to commit, working tree clean\n","Everything up-to-date\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"uQQYRsEG6UIa"},"execution_count":null,"outputs":[]}]}